{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmFdsTvLKtBO"
      },
      "source": [
        "## Note\n",
        "Make sure that your runtime type is 'Python 3 with GPU acceleration'. To do so, go to Edit > Notebook settings > Hardware Accelerator > Select \"GPU\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TfPAtL4CyZw"
      },
      "source": [
        "## More Info\n",
        "- Paper: https://arxiv.org/pdf/2004.00452.pdf\n",
        "- Repo: https://github.com/facebookresearch/pifuhd\n",
        "- Project Page: https://shunsukesaito.github.io/PIFuHD/\n",
        "- 1-minute/5-minute Presentation (see below)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python --version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi-7z_dcSbc7",
        "outputId": "e3cd6e92-dcb4-4d0f-9b84-a2da64da3b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "\n",
        "import condacolab\n",
        "\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g69OwJseSgnC",
        "outputId": "cc020914-02b1-46f1-bc32-e01b03528332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR5I0MC6Shmp",
        "outputId": "6375e8a0-a673-4de8-d6e3-e66293291d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 24.11.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! conda create -n env_name python=3.9.0 # PYTHON_VERSION can be 3.9 or any other releas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRh_iCrBS9FK",
        "outputId": "ac775710-093a-47e0-f600-ce91e610a28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/env_name\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9.0\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2025.1.31-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_4 \n",
            "  libffi             conda-forge/linux-64::libffi-3.3-h58526e2_2 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h767d61c_2 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_2 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h767d61c_2 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_0 \n",
            "  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.8.1-hb9d3cd8_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.46.0-hde9e2c9_0 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-14.2.0-h8f9b012_2 \n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-14.2.0-h4852527_2 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h4ab18f5_6 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-1.1.1w-hd590300_0 \n",
            "  pip                conda-forge/noarch::pip-25.0.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.9.0-hffdb5ce_5_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2 \n",
            "  setuptools         conda-forge/noarch::setuptools-78.1.0-pyhff2d567_0 \n",
            "  sqlite             conda-forge/linux-64::sqlite-3.46.0-h6d4b2fc_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "  xz                 conda-forge/linux-64::xz-5.8.1-hbcc6ac9_0 \n",
            "  xz-gpl-tools       conda-forge/linux-64::xz-gpl-tools-5.8.1-hbcc6ac9_0 \n",
            "  xz-tools           conda-forge/linux-64::xz-tools-5.8.1-hb9d3cd8_0 \n",
            "  zlib               conda-forge/linux-64::zlib-1.2.13-h4ab18f5_6 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate env_name\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n pifu_env python=3.9 -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIqU9viS9Cp",
        "outputId": "1ef2692f-5488-4a8e-bd89-40b29d13e3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.3.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/pifu_env\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h4bc722e_7 \n",
            "  ca-certificates    conda-forge/linux-64::ca-certificates-2025.1.31-hbcca054_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.43-h712a8e2_4 \n",
            "  libffi             conda-forge/linux-64::libffi-3.4.6-h2dba641_1 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h767d61c_2 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-14.2.0-h69a702a_2 \n",
            "  libgomp            conda-forge/linux-64::libgomp-14.2.0-h767d61c_2 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.1-hb9d3cd8_0 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hd590300_0 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.49.1-hee588c1_2 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-3.5.0-h7b32b05_0 \n",
            "  pip                conda-forge/noarch::pip-25.0.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.9.22-h85ef794_0_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.2-h8c095d6_2 \n",
            "  setuptools         conda-forge/noarch::setuptools-78.1.0-pyhff2d567_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h4845f30_101 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025b-h78e105d_0 \n",
            "  wheel              conda-forge/noarch::wheel-0.45.1-pyhd8ed1ab_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate pifu_env\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install --name pifu_env -c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ-UkQwRS8_h",
        "outputId": "72da1701-20e7-4977-e664-3fbfa956442b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: conda install [-h] [--revision REVISION] [-n ENVIRONMENT | -p PATH]\n",
            "                     [-c CHANNEL] [--use-local] [--override-channels]\n",
            "                     [--repodata-fn REPODATA_FNS] [--experimental {jlap,lock}]\n",
            "                     [--no-lock] [--repodata-use-zst | --no-repodata-use-zst]\n",
            "                     [--strict-channel-priority] [--no-channel-priority]\n",
            "                     [--no-deps | --only-deps] [--no-pin] [--copy]\n",
            "                     [--no-shortcuts] [--shortcuts-only SHORTCUTS_ONLY] [-C]\n",
            "                     [-k] [--offline] [--json] [--console CONSOLE] [-v] [-q]\n",
            "                     [-d] [-y] [--download-only] [--show-channel-urls]\n",
            "                     [--file FILE] [--solver {classic,libmamba}]\n",
            "                     [--force-reinstall]\n",
            "                     [--freeze-installed | --update-deps | -S | --update-all | --update-specs]\n",
            "                     [-m] [--clobber] [--dev]\n",
            "                     [package_spec ...]\n",
            "conda install: error: argument -c/--channel: expected one argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda init"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eos_7cpnW5eC",
        "outputId": "329f7edc-0df6-470d-eeec-2725922bcfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.11/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda activate pifu_env"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbcP_bTrS84C",
        "outputId": "624eb9c4-4276-4450-ca40-76ac253e18c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DDpqpf2BABR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "outputId": "700c5340-1c08-46a1-bbbf-54af05755298",
        "collapsed": true
      },
      "source": [
        "import IPython\n",
        "IPython.display.HTML('<h2>1-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/-1XYTmm8HhE\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe><br><h2>5-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/uEDqCxvF5yc\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>1-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/-1XYTmm8HhE\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe><br><h2>5-Minute Presentation</h2><iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/uEDqCxvF5yc\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vZaAyhUJ9QC"
      },
      "source": [
        "## Requirements\n",
        "- Python 3\n",
        "- PyTorch tested on 1.4.0\n",
        "- json\n",
        "- PIL\n",
        "- skimage\n",
        "- tqdm\n",
        "- numpy\n",
        "- cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfPDep8LlP_I"
      },
      "source": [
        "## Help! I'm new to Google Colab\n",
        "\n",
        "You can check out the following youtube video on how to upload your own picture and run PIFuHD. **Note that with new update, you can upload your own picture more easily with GUI down below.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaMP1EitljaA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "c26fc98e-c75b-49af-eb3f-50438cb03abe",
        "collapsed": true
      },
      "source": [
        "import IPython\n",
        "IPython.display.HTML('<iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/LWDGR5v3-3o\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"720\" height=\"405\" src=\"https://www.youtube.com/embed/LWDGR5v3-3o\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYhlsDkg1Hwb"
      },
      "source": [
        "## Clone PIFuHD repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmpEwdOd1G1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "428e756d-b674-4cbd-9163-87cc772642ca"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/pifuhd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pifuhd' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvQm-A8ESKb2"
      },
      "source": [
        "## Configure input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvle9T10fB6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175c5d25-c42b-46f7-c5ff-c5203f355cda"
      },
      "source": [
        "cd /content/pifuhd/sample_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pifuhd/sample_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SI7Ye1JfIim"
      },
      "source": [
        "**If you want to upload your own picture, run the next cell**. Otherwise, go to the next next cell. Currently PNG, JPEG files are supported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEzmmB01SOZp"
      },
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (5).png' % filename\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (6).png' % filename\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (7).png' % filename\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (8).png' % filename\n",
        "\n",
        "except:\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (5).png' # example image\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (6).png' # example image\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (7).png' # example image\n",
        "  image_path = '/content/pifuhd/sample_images/rgb_image (8).png' # example image\n",
        "\n",
        "image_dir = os.path.dirname(image_path)\n",
        "file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "# output pathes\n",
        "obj_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.obj' % file_name\n",
        "out_img_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.png' % file_name\n",
        "video_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.mp4' % file_name\n",
        "video_display_path = '/content/pifuhd/results/pifuhd_final/result_%s_256_display.mp4' % file_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "896EC7iQfXkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38aa923b-5e20-426f-9d75-15ba0db50253"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbVmda9J5TDL"
      },
      "source": [
        "## Preprocess (for cropping image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtMjWGNU5STe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404d1c7d-c892-43b5-f8dc-4665127badbe"
      },
      "source": [
        "!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'lightweight-human-pose-estimation.pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-vYklhI5dab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc44d60-b572-48bd-845d-5753ee830483"
      },
      "source": [
        "cd /content/lightweight-human-pose-estimation.pytorch/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lightweight-human-pose-estimation.pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRod9SOu77I6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1866888-3dfa-4f5f-bb97-2e97fe58dd17"
      },
      "source": [
        "!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-12 06:01:34--  https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\n",
            "Resolving download.01.org (download.01.org)... 92.122.14.20, 2600:1409:9800:168c::a87, 2600:1409:9800:1689::a87\n",
            "Connecting to download.01.org (download.01.org)|92.122.14.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87959810 (84M) [application/octet-stream]\n",
            "Saving to: ‘checkpoint_iter_370000.pth.8’\n",
            "\n",
            "checkpoint_iter_370 100%[===================>]  83.88M   194MB/s    in 0.4s    \n",
            "\n",
            "2025-04-12 06:01:34 (194 MB/s) - ‘checkpoint_iter_370000.pth.8’ saved [87959810/87959810]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdRcDXe38lHB"
      },
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
        "from modules.keypoints import extract_keypoints, group_keypoints\n",
        "from modules.load_state import load_state\n",
        "from modules.pose import Pose, track_poses\n",
        "import demo\n",
        "\n",
        "def get_rect(net, images, height_size):\n",
        "    net = net.eval()\n",
        "\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "    previous_poses = []\n",
        "    delay = 33\n",
        "    for image in images:\n",
        "        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        orig_img = img.copy()\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "        current_poses = []\n",
        "\n",
        "        rects = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "            valid_keypoints = []\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "            valid_keypoints = np.array(valid_keypoints)\n",
        "\n",
        "            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "              pmin = valid_keypoints.min(0)\n",
        "              pmax = valid_keypoints.max(0)\n",
        "\n",
        "              # Replace np.int with int to avoid the AttributeError\n",
        "              center = (0.5 * (pmax[:2] + pmin[:2])).astype(int)\n",
        "              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n",
        "            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n",
        "              # if leg is missing, use pelvis to get cropping\n",
        "              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(int) # Replace np.int with int\n",
        "              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "              center[1] += int(0.05*radius)\n",
        "            else:\n",
        "              center = np.array([img.shape[1]//2,img.shape[0]//2])\n",
        "              radius = max(img.shape[1]//2,img.shape[0]//2)\n",
        "\n",
        "            x1 = center[0] - radius\n",
        "            y1 = center[1] - radius\n",
        "\n",
        "            rects.append([x1, y1, 2*radius, 2*radius])\n",
        "\n",
        "        np.savetxt(rect_path, np.array(rects), fmt='%d')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6cGZD6f6IaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c2cb31-e708-47fc-ce95-779adb5e69b1"
      },
      "source": [
        "net = PoseEstimationWithMobileNet()\n",
        "checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n",
        "load_state(net, checkpoint)\n",
        "\n",
        "get_rect(net.cuda(), [image_path], 512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-736a0682666b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0rgMInwTt0s"
      },
      "source": [
        "## Download the Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrIcZweSNRFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d02788-98d2-4a0c-d363-31cadd0f41a6"
      },
      "source": [
        "cd /content/pifuhd/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pifuhd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3jjm6HuQRk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e97920e-6365-4757-f3a1-2dc528f08773"
      },
      "source": [
        "!sh ./scripts/download_trained_model.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ mkdir -p checkpoints\n",
            "+ cd checkpoints\n",
            "+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n",
            "--2025-04-12 06:01:37--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.96, 3.163.189.51, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548375177 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘pifuhd.pt.7’\n",
            "\n",
            "pifuhd.pt.7         100%[===================>]   1.44G   107MB/s    in 7.9s    \n",
            "\n",
            "2025-04-12 06:01:45 (186 MB/s) - ‘pifuhd.pt.7’ saved [1548375177/1548375177]\n",
            "\n",
            "--2025-04-12 06:01:45--  http://pifuhd.pt/\n",
            "Resolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘pifuhd.pt’\n",
            "FINISHED --2025-04-12 06:01:45--\n",
            "Total wall clock time: 8.1s\n",
            "Downloaded: 1 files, 1.4G in 7.9s (186 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6heKcA-0QEBw"
      },
      "source": [
        "## Run PIFuHD!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKTiafj4YtdM",
        "outputId": "d58e05bf-14c4-444c-a0fe-73f1776b4b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/site-packages (from opencv-python-headless) (2.2.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e8ALfFSZdgE",
        "outputId": "bffbc61c-58dd-4b90-ee3e-6788edb31dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.5.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/site-packages (0.20.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/site-packages (2.5.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/site-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/site-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/site-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/site-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from torchvision) (2.2.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np1QYTApaf1z",
        "outputId": "d5a94887-ed8b-4d90-eba5-359acff23ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/site-packages (from matplotlib) (2.2.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX matplotlib backend issue + ensure dependencies\n",
        "!pip install matplotlib opencv-python-headless numpy torch torchvision\n",
        "\n",
        "# Set a compatible backend for Colab\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Use non-interactive backend suitable for Colab\n",
        "\n",
        "# Optional: check installed versions\n",
        "import torch, cv2, matplotlib\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "print(\"OpenCV version:\", cv2.__version__)\n",
        "print(\"Matplotlib backend:\", matplotlib.get_backend())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRcqqQ-lbSvc",
        "outputId": "85e50d4d-b304-45e9-9416-ffef5a78d964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (3.10.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (2.2.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.5.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/site-packages (0.20.0+cu118)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/site-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/site-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/site-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/site-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/site-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
            "Torch version: 2.5.0+cu118\n",
            "OpenCV version: 4.11.0\n",
            "Matplotlib backend: Agg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "\n"
      ],
      "metadata": {
        "id": "0rLIOgc5bzVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n"
      ],
      "metadata": {
        "id": "yFDtGgiHcVC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4bh8DG0clgU",
        "outputId": "198a4be8-0770-4018-c18b-0686b3bc8d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/site-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/site-packages (from scikit-image) (2.2.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/site-packages (from scikit-image) (1.15.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/site-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/site-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/site-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/site-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/site-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/site-packages (from scikit-image) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5995t2PnQTmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d48bc7-7175-42b3-b1e0-157feb7ae354"
      },
      "source": [
        "# Warning: all images with the corresponding rectangle files under -i will be processed.\n",
        "!python -m apps.simple_test -r 256 --use_rect -i /content/pifuhd/sample_images\n",
        "\n",
        "\n",
        "\n",
        "# seems that 256 is the maximum resolution that can fit into Google Colab.\n",
        "# If you want to reconstruct a higher-resolution mesh, please try with your own machine."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from  ./checkpoints/pifuhd.pt\n",
            "/content/pifuhd/apps/recon.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(state_dict_path, map_location=cuda)\n",
            "Warning: opt is overwritten.\n",
            "test data size:  4\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "generate mesh (test) ...\n",
            "  0% 0/4 [00:00<?, ?it/s]./results/pifuhd_final/recon/result_rgb_image (5)_256.obj\n",
            "[ WARN:0@14.368] global loadsave.cpp:848 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n",
            " 25% 1/4 [00:05<00:16,  5.53s/it]./results/pifuhd_final/recon/result_rgb_image (6)_256.obj\n",
            " 50% 2/4 [00:11<00:11,  5.74s/it]./results/pifuhd_final/recon/result_rgb_image (7)_256.obj\n",
            " 75% 3/4 [00:16<00:05,  5.49s/it]./results/pifuhd_final/recon/result_rgb_image (8)_256.obj\n",
            "100% 4/4 [00:21<00:00,  5.45s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUZ8Nt5rNFXZ"
      },
      "source": [
        "## Render the result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define version_str for PyTorch3D installation\n",
        "import sys\n",
        "import torch\n",
        "pyt_version_str = torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "version_str = \"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\", \"\"),\n",
        "    f\"_pyt{pyt_version_str}\"\n",
        "])"
      ],
      "metadata": {
        "id": "50Fi-rg9REdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install PyTorch3D dependencies\n",
        "!pip install -U fvcore iopath\n",
        "\n",
        "# Step 2: Install PyTorch3D using the correct wheel\n",
        "!pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py3.9_cu117_pyt1120/download.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcXjBlOlQYnY",
        "outputId": "beca11ac-6cc7-4298-c1d0-dce508528cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/site-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/site-packages (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from fvcore) (2.2.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/site-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (3.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/site-packages (from fvcore) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/site-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from iopath) (4.13.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/site-packages (from iopath) (3.1.1)\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py3.9_cu117_pyt1120/download.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch3d (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch3d\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install fvcore iopath\n",
        "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html"
      ],
      "metadata": {
        "id": "hr32nM0mRs6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53335c2-54a1-4510-e13e-b96f82881beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/site-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/site-packages (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from fvcore) (2.2.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/site-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (3.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/site-packages (from fvcore) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/site-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from iopath) (4.13.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/site-packages (from iopath) (3.1.1)\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py311_cu118_pyt250/download.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch3d (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch3d\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xp5s5uiOiDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b394ae88-57e0-4a9e-9d26-32d8121f87c3"
      },
      "source": [
        "import sys\n",
        "import torch\n",
        "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{pyt_version_str}\"\n",
        "])\n",
        "!pip install fvcore iopath\n",
        "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/site-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/site-packages (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from fvcore) (2.2.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/site-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (3.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/site-packages (from fvcore) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/site-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from iopath) (4.13.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/site-packages (from iopath) (3.1.1)\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py311_cu118_pyt250/download.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch3d (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch3d\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore iopath\n",
        "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html"
      ],
      "metadata": {
        "id": "xRn6E0CNQk-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5682803e-6e71-4882-832c-29291725f7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/site-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.11/site-packages (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from fvcore) (2.2.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/site-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/site-packages (from fvcore) (3.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/site-packages (from fvcore) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/site-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/site-packages (from iopath) (4.13.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/site-packages (from iopath) (3.1.1)\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py311_cu118_pyt250/download.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch3d (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch3d\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afwL_-ROCmDf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "d31def7c-dd6c-4743-e86d-5a1be101a1af"
      },
      "source": [
        "from lib.colab_util import generate_video_from_obj, set_renderer, video\n",
        "\n",
        "renderer = set_renderer()\n",
        "generate_video_from_obj(obj_path, out_img_path, video_path, renderer)\n",
        "\n",
        "# we cannot play a mp4 video generated by cv2\n",
        "!ffmpeg -i $video_path -vcodec libx264 $video_display_path -y -loglevel quiet\n",
        "video(video_display_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pytorch3d'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-22614b7ef849>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_video_from_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_renderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerate_video_from_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_img_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pifuhd/lib/colab_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Util function for loading meshes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_objs_as_meshes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch3d'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUEXAvcvkVYV"
      },
      "source": [
        "## Tips for Inputs: My results are broken!\n",
        "\n",
        "(Kudos to those who share results on twitter with [#pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live) tag!!!!)\n",
        "\n",
        "Due to the limited variation in the training data, your results might be broken sometimes. Here I share some useful tips to get resonable results.\n",
        "\n",
        "*   Use high-res image. The model is trained with 1024x1024 images. Use at least 512x512 with fine-details. Low-res images and JPEG artifacts may result in unsatisfactory results.\n",
        "*   Use an image with a single person. If the image contain multiple people, reconstruction quality is likely degraded.\n",
        "*   Front facing with standing works best (or with fashion pose)\n",
        "*   The entire body is covered within the image. (Note: now missing legs is partially supported)\n",
        "*   Make sure the input image is well lit. Exteremy dark or bright image and strong shadow often create artifacts.\n",
        "*   I recommend nearly parallel camera angle to the ground. High camera height may result in distorted legs or high heels.\n",
        "*   If the background is cluttered, use less complex background or try removing it using https://www.remove.bg/ before processing.\n",
        "*   It's trained with human only. Anime characters may not work well (To my surprise, indeed many people tried it!!).\n",
        "*   Search on twitter with [#pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live) tag to get a better sense of what succeeds and what fails.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6U0K5CNAO_u"
      },
      "source": [
        "## Share your result!\n",
        "Please share your results with[ #pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live) tag on Twitter. Sharing your good/bad results helps and encourages the authors to further push towards producition-quality human digitization at home.\n",
        "**As the tweet buttom below doesn't add the result video automatically, please download the result video above and manually add it to the tweet.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CBxbdrM9F-9"
      },
      "source": [
        "import IPython\n",
        "IPython.display.HTML('<a href=\"https://twitter.com/intent/tweet?button_hashtag=pifuhd&ref_src=twsrc%5Etfw\" class=\"twitter-hashtag-button\" data-size=\"large\" data-text=\"Google Colab Link: \" data-url=\"https://bit.ly/37sfogZ\" data-show-count=\"false\">Tweet #pifuhd</a><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>  (Don\\'t forget to add your result to the tweet!)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-1pR8UR7PR"
      },
      "source": [
        "## Cool Applications\n",
        "Special thanks to those who play with PIFuHD and came up with many creative applications!! If you made any cool applications, please tweet your demo with [#pifuhd](https://twitter.com/search?q=%23pifuhd&src=recent_search_click&f=live). I'm constantly checking results there.\n",
        "If you need complete texture on the mesh, please try my previous work [PIFu](https://github.com/shunsukesaito/PIFu) as well! It supports 3D reconstruction + texturing from a single image although the geometry quality may not be as good as PIFuHD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68JDAYJFSFMV"
      },
      "source": [
        "IPython.display.HTML('<h2>Rigging (Mixamo) + Photoreal Rendering (Blender)</h2><blockquote class=\"twitter-tweet\"><p lang=\"pt\" dir=\"ltr\">vcs ainda tem a PACHORRA de me dizer que eu não sei dançar<a href=\"https://twitter.com/hashtag/b3d?src=hash&amp;ref_src=twsrc%5Etfw\">#b3d</a> <a href=\"https://twitter.com/hashtag/pifuhd?src=hash&amp;ref_src=twsrc%5Etfw\">#pifuhd</a> <a href=\"https://t.co/kHCnLh6zxH\">pic.twitter.com/kHCnLh6zxH</a></p>&mdash; lukas arendero (@lukazvd) <a href=\"https://twitter.com/lukazvd/status/1274810484798128131?ref_src=twsrc%5Etfw\">June 21, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><h2>FaceApp + Rigging (Mixamo)</h2><blockquote class=\"twitter-tweet\"><p lang=\"ja\" dir=\"ltr\">カツラかぶってる自分に見える <a href=\"https://twitter.com/hashtag/pifuhd?src=hash&amp;ref_src=twsrc%5Etfw\">#pifuhd</a> <a href=\"https://t.co/V8o7VduTiG\">pic.twitter.com/V8o7VduTiG</a></p>&mdash; Shuhei Tsuchida (@shuhei2306) <a href=\"https://twitter.com/shuhei2306/status/1274507242910314498?ref_src=twsrc%5Etfw\">June 21, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><h2>Rigging (Mixamo) + AR (Adobe Aero)</AR><blockquote class=\"twitter-tweet\"><p lang=\"ja\" dir=\"ltr\">写真→PIFuHD→Mixamo→AdobeAeroでサウンド付きARを作成。Zip化してLINEでARコンテンツを共有。<br>写真が1枚あれば簡単にARの3Dアニメーションが作れる時代…凄い。<a href=\"https://twitter.com/hashtag/PIFuHD?src=hash&amp;ref_src=twsrc%5Etfw\">#PIFuHD</a> <a href=\"https://twitter.com/hashtag/AdobeAero?src=hash&amp;ref_src=twsrc%5Etfw\">#AdobeAero</a> <a href=\"https://twitter.com/hashtag/Mixamo?src=hash&amp;ref_src=twsrc%5Etfw\">#Mixamo</a> <a href=\"https://t.co/CbiMi4gZ0K\">pic.twitter.com/CbiMi4gZ0K</a></p>&mdash; モジョン (@mojon1) <a href=\"https://twitter.com/mojon1/status/1273217947872317441?ref_src=twsrc%5Etfw\">June 17, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script><h2>3D Printing</h2><blockquote class=\"twitter-tweet\"><p lang=\"ja\" dir=\"ltr\"><a href=\"https://twitter.com/hashtag/pifuhd?src=hash&amp;ref_src=twsrc%5Etfw\">#pifuhd</a> 楽しい〜<br>小さい自分プリントした <a href=\"https://t.co/4qyWuij0Hs\">pic.twitter.com/4qyWuij0Hs</a></p>&mdash; isb (@vxzxzxzxv) <a href=\"https://twitter.com/vxzxzxzxv/status/1273136266406694913?ref_src=twsrc%5Etfw\">June 17, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX5CTTW_KWhQ"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Load the .npy files\n",
        "rgb_image = np.load(\"rgb_image new.npy\")\n",
        "depthmap = np.load(\"depthmap.npy\").squeeze()\n",
        "inpainted_depthmap = np.load(\"inpainted_depthmap.npy\").squeeze()\n",
        "connected_component = np.load(\"connected_component.npy\")\n",
        "\n",
        "# Normalize and convert helper\n",
        "def normalize_and_convert(arr):\n",
        "    arr_norm = (255 * (arr - np.min(arr)) / (np.ptp(arr))).astype(np.uint8)\n",
        "    return Image.fromarray(arr_norm)\n",
        "\n",
        "# Save RGB image\n",
        "if rgb_image.max() <= 1.0:\n",
        "    rgb_image = (rgb_image * 255).astype(np.uint8)\n",
        "Image.fromarray(rgb_image).save(\"rgb_image.png\")\n",
        "\n",
        "# Save others\n",
        "normalize_and_convert(depthmap).save(\"depthmap.png\")\n",
        "normalize_and_convert(inpainted_depthmap).save(\"inpainted_depthmap.png\")\n",
        "normalize_and_convert(connected_component).save(\"connected_component.png\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "bURz0pg47Xq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COVERTING OF NPY FILES TO PNG FILES\n"
      ],
      "metadata": {
        "id": "IKNCmXp2Et_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "output_dir = \"rgb_png_output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get all .npy files in current directory\n",
        "npy_files = [f for f in os.listdir() if f.endswith(\".npy\") and \"rgb_image\" in f]\n",
        "\n",
        "# Convert each RGB .npy file to PNG\n",
        "for npy_file in npy_files:\n",
        "    rgb_image = np.load(npy_file)\n",
        "\n",
        "    # If values are in range 0–1, convert to 0–255\n",
        "    if rgb_image.max() <= 1.0:\n",
        "        rgb_image = (rgb_image * 255).astype(np.uint8)\n",
        "\n",
        "    # Save image as PNG\n",
        "    image = Image.fromarray(rgb_image)\n",
        "    output_path = os.path.join(output_dir, npy_file.replace(\".npy\", \".png\"))\n",
        "    image.save(output_path)\n",
        "    print(f\"✅ Saved: {output_path}\")\n"
      ],
      "metadata": {
        "id": "Wlz0Jq07Djpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.5.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "metadata": {
        "id": "4kjuTq9CdHl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g9JKrTNKXRtU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}